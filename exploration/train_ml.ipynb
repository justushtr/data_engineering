{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Furniture' 'Office Supplies' 'Technology']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"category\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def model_training_tuning_extended(df_ml, features: list, target: str):\n",
    "    X = df_ml[features]\n",
    "    y = df_ml[target]\n",
    "    categorical_features = ['sub_category', 'region', 'segment']\n",
    "\n",
    "    # One-Hot Encoding\n",
    "    X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
    "\n",
    "    models = {\n",
    "        \"LinearRegression\": LinearRegression(),\n",
    "        \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "        \"GradientBoosting\": GradientBoostingRegressor(random_state=42)\n",
    "    }\n",
    "\n",
    "    # Erweiterter Parameterraum\n",
    "    param_grids = {\n",
    "        \"LinearRegression\": {}, # LR hat keine nennenswerten Hyperparameter\n",
    "        \n",
    "        \"RandomForest\": {\n",
    "            'n_estimators': [200, 500],        # Mehr Bäume\n",
    "            'max_depth': [10, 20, 30, None],   # Tiefere Bäume erlaubt\n",
    "            'min_samples_split': [2, 5, 10],   # Verhindert Overfitting\n",
    "            'min_samples_leaf': [1, 2, 4]      # Wie viele Datenpunkte min. pro Blatt?\n",
    "        },\n",
    "        \n",
    "        \"GradientBoosting\": {\n",
    "            'n_estimators': [200, 500],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7],            # GB profitiert oft von flacheren Bäumen als RF\n",
    "            'subsample': [0.8, 1.0]            # Trainiert jeden Baum nur auf 80% der Daten (Stochastik)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Wir definieren mehrere Metriken, die getrackt werden sollen\n",
    "    scoring_metrics = {\n",
    "        'R2': 'r2',\n",
    "        'MAE': 'neg_mean_absolute_error',\n",
    "        'RMSE': 'neg_root_mean_squared_error'\n",
    "    }\n",
    "\n",
    "    results_summary = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Starte Tuning für: {name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        if not param_grids[name]:\n",
    "            # Fallback für LinearRegression ohne Grid\n",
    "            from sklearn.model_selection import cross_validate\n",
    "            scores = cross_validate(model, X_encoded, y, cv=5, scoring=scoring_metrics)\n",
    "            print(f\"Keine Parameter zu tunen. Standard-Ergebnisse:\")\n",
    "            print(f\"R2: {scores['test_R2'].mean():.4f} | MAE: {-scores['test_MAE'].mean():.2f} | RMSE: {-scores['test_RMSE'].mean():.2f}\")\n",
    "            results_summary[name] = model.fit(X_encoded, y)\n",
    "            continue\n",
    "\n",
    "        # GridSearchCV Setup\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grids[name],\n",
    "            cv=5,\n",
    "            scoring=scoring_metrics,\n",
    "            refit='R2', # Welcher Wert entscheidet über den \"Sieger\"?\n",
    "            n_jobs=-1,\n",
    "            verbose=1   # Zeigt Fortschrittsbalken/Logs an\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_encoded, y)\n",
    "        \n",
    "        # --- Auswertung aller Kombinationen ---\n",
    "        results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "        \n",
    "        # Wir wählen nur die relevanten Spalten für den Print\n",
    "        cols_to_keep = ['params', 'mean_test_R2', 'mean_test_MAE', 'mean_test_RMSE']\n",
    "        view_df = results_df[cols_to_keep].copy()\n",
    "        \n",
    "        # Scikit-Learn gibt Fehler als negative Werte zurück (damit \"max\" besser ist).\n",
    "        # Wir machen sie für die Anzeige wieder positiv:\n",
    "        view_df['mean_test_MAE'] = -view_df['mean_test_MAE']\n",
    "        view_df['mean_test_RMSE'] = -view_df['mean_test_RMSE']\n",
    "        \n",
    "        # Sortieren nach R2 (bestes oben)\n",
    "        view_df = view_df.sort_values(by='mean_test_R2', ascending=False)\n",
    "\n",
    "        print(f\"\\nAlle getesteten Kombinationen für {name} (Top 10 Auszug):\")\n",
    "        print(\"-\" * 100)\n",
    "        # Formatierte Ausgabe der Tabelle\n",
    "        print(f\"{'R2':<10} | {'MAE':<10} | {'RMSE':<10} | {'Parameters'}\")\n",
    "        print(\"-\" * 100)\n",
    "        \n",
    "        # Iterieren und printen (hier alle, oder slicing [0:20] nutzen wenn es zu viele sind)\n",
    "        for index, row in view_df.iterrows():\n",
    "            params_str = str(row['params'])\n",
    "            print(f\"{row['mean_test_R2']:<10.4f} | {row['mean_test_MAE']:<10.2f} | {row['mean_test_RMSE']:<10.2f} | {params_str}\")\n",
    "\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"BESTER {name}: R2={grid_search.best_score_:.4f}\")\n",
    "        print(f\"Beste Params: {grid_search.best_params_}\")\n",
    "        \n",
    "        results_summary[name] = grid_search.best_estimator_\n",
    "\n",
    "    return results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Starte Tuning für: LinearRegression\n",
      "================================================================================\n",
      "Keine Parameter zu tunen. Standard-Ergebnisse:\n",
      "R2: 0.7277 | MAE: 36.91 | RMSE: 109.32\n",
      "\n",
      "================================================================================\n",
      "Starte Tuning für: RandomForest\n",
      "================================================================================\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      "Alle getesteten Kombinationen für RandomForest (Top 10 Auszug):\n",
      "----------------------------------------------------------------------------------------------------\n",
      "R2         | MAE        | RMSE       | Parameters\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0.7213     | 18.88      | 106.03     | {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "0.7211     | 19.09      | 107.43     | {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "0.7209     | 19.00      | 107.35     | {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "0.7206     | 18.86      | 106.10     | {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "0.7203     | 18.55      | 107.10     | {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "0.7197     | 18.65      | 107.03     | {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "0.7194     | 19.01      | 107.61     | {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "0.7190     | 18.99      | 106.52     | {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "0.7187     | 18.55      | 107.27     | {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "0.7136     | 23.93      | 109.09     | {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "0.7132     | 23.75      | 108.87     | {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "0.7129     | 23.84      | 107.93     | {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "0.7118     | 18.35      | 106.27     | {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "0.7070     | 18.88      | 107.20     | {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "0.7068     | 18.87      | 107.06     | {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "0.7049     | 18.39      | 107.23     | {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "0.7045     | 18.99      | 107.46     | {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "0.7043     | 19.01      | 108.59     | {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "0.7041     | 18.50      | 107.30     | {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "0.7041     | 19.11      | 108.82     | {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "0.7037     | 19.82      | 114.13     | {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 500}\n",
      "0.7037     | 19.76      | 114.09     | {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 500}\n",
      "0.7037     | 18.67      | 108.61     | {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "0.7036     | 19.76      | 114.11     | {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 500}\n",
      "0.7032     | 18.61      | 108.90     | {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "0.7032     | 19.02      | 108.81     | {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "0.7018     | 19.41      | 113.97     | {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 500}\n",
      "0.7018     | 18.61      | 109.30     | {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "0.7016     | 19.42      | 114.02     | {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 500}\n",
      "0.7015     | 19.52      | 114.01     | {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 500}\n",
      "0.6994     | 20.78      | 118.47     | {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "0.6994     | 20.78      | 118.47     | {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "0.6993     | 20.76      | 118.49     | {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "0.6993     | 20.76      | 118.49     | {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "0.6991     | 23.67      | 109.31     | {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "0.6989     | 20.76      | 118.54     | {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "0.6989     | 20.76      | 118.54     | {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "0.6978     | 24.48      | 115.45     | {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 500}\n",
      "0.6975     | 23.76      | 109.01     | {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "0.6972     | 23.72      | 110.49     | {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "0.6969     | 18.36      | 107.65     | {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "0.6969     | 18.37      | 108.04     | {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "0.6965     | 23.87      | 110.53     | {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "0.6948     | 24.97      | 119.49     | {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "0.6948     | 24.97      | 119.49     | {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "0.6940     | 24.38      | 115.73     | {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 500}\n",
      "0.6930     | 20.97      | 120.23     | {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 500}\n",
      "0.6929     | 20.97      | 120.23     | {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 500}\n",
      "0.6929     | 20.99      | 120.25     | {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 500}\n",
      "0.6892     | 20.86      | 119.81     | {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "0.6892     | 20.86      | 119.81     | {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "0.6888     | 25.14      | 121.13     | {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 500}\n",
      "0.6888     | 20.83      | 119.85     | {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "0.6888     | 20.83      | 119.85     | {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "0.6883     | 20.84      | 119.92     | {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "0.6883     | 20.84      | 119.92     | {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "0.6857     | 19.93      | 116.19     | {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "0.6855     | 19.87      | 116.11     | {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "0.6854     | 18.53      | 109.17     | {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "0.6854     | 19.88      | 116.17     | {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "0.6839     | 24.97      | 120.93     | {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "0.6839     | 24.97      | 120.93     | {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "0.6836     | 19.48      | 116.06     | {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "0.6834     | 19.49      | 116.12     | {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "0.6830     | 23.62      | 111.04     | {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "0.6822     | 19.60      | 116.37     | {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "0.6820     | 21.04      | 121.62     | {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "0.6819     | 21.04      | 121.64     | {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "0.6818     | 21.07      | 121.68     | {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "0.6801     | 24.50      | 117.36     | {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "0.6776     | 25.13      | 122.55     | {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "0.6758     | 24.40      | 117.87     | {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BESTER RandomForest: R2=0.7213\n",
      "Beste Params: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "\n",
      "================================================================================\n",
      "Starte Tuning für: GradientBoosting\n",
      "================================================================================\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "\n",
      "Alle getesteten Kombinationen für GradientBoosting (Top 10 Auszug):\n",
      "----------------------------------------------------------------------------------------------------\n",
      "R2         | MAE        | RMSE       | Parameters\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0.8587     | 16.47      | 81.25      | {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.8513     | 18.75      | 83.54      | {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
      "0.8419     | 17.59      | 81.12      | {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.8295     | 17.56      | 84.71      | {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 500, 'subsample': 1.0}\n",
      "0.8288     | 21.25      | 85.68      | {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
      "0.8207     | 16.20      | 85.63      | {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500, 'subsample': 1.0}\n",
      "0.8207     | 15.22      | 86.59      | {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 500, 'subsample': 1.0}\n",
      "0.8176     | 17.01      | 87.73      | {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\n",
      "0.8172     | 21.32      | 89.28      | {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\n",
      "0.8150     | 18.37      | 87.57      | {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\n",
      "0.8097     | 15.91      | 90.15      | {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.8051     | 17.72      | 91.45      | {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
      "0.7873     | 27.71      | 97.43      | {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.7817     | 14.51      | 94.69      | {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.7806     | 15.39      | 94.91      | {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "0.7635     | 27.86      | 102.64     | {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500, 'subsample': 1.0}\n",
      "0.7606     | 14.54      | 94.67      | {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.7587     | 15.96      | 95.20      | {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "0.7273     | 15.44      | 100.10     | {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.7227     | 21.68      | 102.96     | {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.7218     | 17.73      | 101.81     | {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "0.7155     | 14.15      | 99.66      | {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 500, 'subsample': 1.0}\n",
      "0.7146     | 15.03      | 99.88      | {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0}\n",
      "0.7088     | 14.84      | 103.12     | {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.7087     | 15.15      | 103.17     | {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "0.7017     | 14.21      | 99.70      | {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.6991     | 16.00      | 100.58     | {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "0.6953     | 19.34      | 103.21     | {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.6917     | 14.50      | 103.35     | {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500, 'subsample': 1.0}\n",
      "0.6910     | 15.65      | 104.13     | {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 500, 'subsample': 1.0}\n",
      "0.6894     | 16.06      | 103.95     | {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0}\n",
      "0.6873     | 17.86      | 105.39     | {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0}\n",
      "0.6856     | 14.09      | 103.14     | {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.6846     | 14.96      | 103.39     | {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "0.6746     | 28.36      | 115.98     | {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "0.6627     | 21.45      | 109.80     | {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500, 'subsample': 1.0}\n",
      "0.6257     | 14.70      | 109.63     | {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 500, 'subsample': 1.0}\n",
      "0.6233     | 16.31      | 110.30     | {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200, 'subsample': 1.0}\n",
      "0.6217     | 34.81      | 127.36     | {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "0.6113     | 43.73      | 134.63     | {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
      "0.6082     | 19.27      | 112.67     | {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500, 'subsample': 1.0}\n",
      "0.6066     | 14.54      | 113.06     | {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 500, 'subsample': 1.0}\n",
      "0.6065     | 14.92      | 113.10     | {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200, 'subsample': 1.0}\n",
      "0.6063     | 14.13      | 112.02     | {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500, 'subsample': 1.0}\n",
      "0.6055     | 15.07      | 112.23     | {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 1.0}\n",
      "0.6028     | 28.27      | 122.64     | {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'subsample': 1.0}\n",
      "0.5970     | 42.48      | 136.90     | {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\n",
      "0.5560     | 34.36      | 133.15     | {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BESTER GradientBoosting: R2=0.8587\n",
      "Beste Params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500, 'subsample': 0.8}\n",
      "{'LinearRegression': LinearRegression(), 'RandomForest': RandomForestRegressor(min_samples_leaf=2, n_estimators=500, random_state=42), 'GradientBoosting': GradientBoostingRegressor(n_estimators=500, random_state=42, subsample=0.8)}\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'sales', 'quantity', \"original_price_per_unit\", \"markdown_amount\",\n",
    "    'sub_category', 'region', 'segment'\n",
    "]\n",
    "target = 'profit'\n",
    "best_models = model_training_tuning_extended(df, features, target)\n",
    "print(best_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trianing(df_ml, features : list, target : str):\n",
    "    X = df_ml[features]\n",
    "    y = df_ml[target]\n",
    "    categorical_features = ['sub_category', 'region', 'segment','order_month', 'order_week_of_year']\n",
    "\n",
    "    X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
    "    \n",
    "    models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "        max_depth=20,        \n",
    "        min_samples_leaf=2, \n",
    "        min_samples_split=5,\n",
    "        n_estimators=500, \n",
    "        random_state=42, \n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(\n",
    "        n_estimators=500, \n",
    "        random_state=42, \n",
    "        subsample=0.8\n",
    "    ),\n",
    "    }\n",
    "\n",
    "    print(f\"{'Model':<20} | {'R2 Score (Mean)':<15} | {'MAE (Mean USD)':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for name, model in models.items():\n",
    "        cv_r2 = cross_val_score(model, X_encoded, y, cv=5, scoring='r2')\n",
    "        cv_mae = cross_val_score(model, X_encoded, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "        print(f\"{name:<20} | {cv_r2.mean():<15.4f} | {-cv_mae.mean():<15.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beste Feature-Wahl: features = 'sales', 'quantity', \"original_price_per_unit\", \"markdown_amount\", 'sub_category', 'region', 'segment', 'order_month'\n",
    "\n",
    "Beste Parameter RF:  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=500, random_state=42, \n",
    "\n",
    "Beste Parameter GB:  n_estimators=500, random_state=42, subsample=0.8\n",
    "\n",
    "Bestes Modell bei dieser Kombination: GB mit R2-SCore 0.8648 und MAE 16.59\n",
    "\n",
    "Problem: MAE ist fast doppelt so groß wie Median Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                | R2 Score (Mean) | MAE (Mean USD) \n",
      "------------------------------------------------------------\n",
      "LinearRegression     | 0.7270          | 37.15          \n",
      "RandomForest         | 0.7142          | 19.33          \n",
      "GradientBoosting     | 0.8648          | 16.59          \n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'sales', 'quantity', \"original_price_per_unit\", \"markdown_amount\",\n",
    "    'sub_category', 'region', 'segment', 'order_month'\n",
    "]\n",
    "target = 'profit'\n",
    "model_trianing(df, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "def model_training_refined(df_ml, features: list, target: str):\n",
    "    # 1. Datenvorbereitung\n",
    "    X = df_ml[features]\n",
    "    y = df_ml[target]\n",
    "    categorical_features = [f for f in ['sub_category', 'region', 'segment', 'order_month', 'order_week_of_year'] if f in features]\n",
    "\n",
    "    # One-Hot-Encoding\n",
    "    X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
    "    \n",
    "    # 2. Train-Test-Split (80% Training, 20% Test)\n",
    "    # Das Testset bleibt völlig unangetastet bis zur finalen Bewertung\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        \"LinearRegression\": LinearRegression(),\n",
    "        \"RandomForest\": RandomForestRegressor(max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=500, random_state=42),\n",
    "        \"GradientBoosting\": GradientBoostingRegressor(n_estimators=500, random_state=42, subsample=0.8),\n",
    "    }\n",
    "\n",
    "    print(f\"{'Model':<20} | {'R2 (CV)':<10} | {'MAE':<10} | {'RMSE':<10} | {'MAPE (%)':<10}\")\n",
    "    print(\"-\" * 75)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        # 3. Cross-Validation auf den Trainingsdaten\n",
    "        # Wir nutzen cross_validate für mehrere Metriken gleichzeitig\n",
    "        scoring = ['r2', 'neg_mean_absolute_error', 'neg_root_mean_squared_error']\n",
    "        cv_results = cross_validate(model, X_train, y_train, cv=5, scoring=scoring)\n",
    "        \n",
    "        # 4. Finales Training auf dem kompletten Trainingsset & Test auf Hold-out-Daten\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Metriken berechnen\n",
    "        mae = -cv_results['test_neg_mean_absolute_error'].mean()\n",
    "        rmse = -cv_results['test_neg_root_mean_squared_error'].mean()\n",
    "        r2 = cv_results['test_r2'].mean()\n",
    "        # MAPE (Mean Absolute Percentage Error) gibt Aufschluss über relative Abweichungen\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
    "\n",
    "        print(f\"{name:<20} | {r2:<10.3f} | {mae:<10.2f} | {rmse:<10.2f} | {mape:<10.2f}%\")\n",
    "        \n",
    "        results[name] = model\n",
    "\n",
    "    return results, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                | R2 (CV)    | MAE        | RMSE       | MAPE (%)  \n",
      "---------------------------------------------------------------------------\n",
      "LinearRegression     | 0.831      | 35.29      | 92.76      | 244323318668277536.00%\n",
      "RandomForest         | 0.764      | 19.40      | 101.30     | 194182599459704768.00%\n",
      "GradientBoosting     | 0.853      | 16.66      | 82.01      | 102308756232426032.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'LinearRegression': LinearRegression(),\n",
       "  'RandomForest': RandomForestRegressor(max_depth=20, min_samples_leaf=2, min_samples_split=5,\n",
       "                        n_estimators=500, random_state=42),\n",
       "  'GradientBoosting': GradientBoostingRegressor(n_estimators=500, random_state=42, subsample=0.8)},\n",
       "         sales  quantity  original_price_per_unit  markdown_amount  \\\n",
       " 3125  563.808         4                   176.19     1.409520e+02   \n",
       " 1441   36.672         2                    22.92     9.168000e+00   \n",
       " 4510   37.300         2                    18.65     0.000000e+00   \n",
       " 39    212.058         3                   100.98     9.088200e+01   \n",
       " 4509  171.288         3                    71.37     4.282200e+01   \n",
       " ...       ...       ...                      ...              ...   \n",
       " 9956   46.350         5                     9.27    -7.105427e-15   \n",
       " 1561    2.780         1                     2.78     0.000000e+00   \n",
       " 1670   16.680         3                     6.95     4.170000e+00   \n",
       " 6951  479.988         2                   399.99     3.199920e+02   \n",
       " 3910  352.450         5                   140.98     3.524500e+02   \n",
       " \n",
       "       sub_category_Appliances  sub_category_Art  sub_category_Binders  \\\n",
       " 3125                    False             False                 False   \n",
       " 1441                    False             False                  True   \n",
       " 4510                    False             False                 False   \n",
       " 39                      False             False                 False   \n",
       " 4509                    False             False                 False   \n",
       " ...                       ...               ...                   ...   \n",
       " 9956                    False             False                 False   \n",
       " 1561                    False              True                 False   \n",
       " 1670                    False             False                 False   \n",
       " 6951                    False             False                 False   \n",
       " 3910                    False             False                 False   \n",
       " \n",
       "       sub_category_Bookcases  sub_category_Chairs  sub_category_Copiers  ...  \\\n",
       " 3125                   False                False                 False  ...   \n",
       " 1441                   False                False                 False  ...   \n",
       " 4510                   False                False                 False  ...   \n",
       " 39                     False                 True                 False  ...   \n",
       " 4509                   False                False                 False  ...   \n",
       " ...                      ...                  ...                   ...  ...   \n",
       " 9956                   False                False                 False  ...   \n",
       " 1561                   False                False                 False  ...   \n",
       " 1670                   False                False                 False  ...   \n",
       " 6951                   False                False                 False  ...   \n",
       " 3910                    True                False                 False  ...   \n",
       " \n",
       "       order_month_3  order_month_4  order_month_5  order_month_6  \\\n",
       " 3125          False          False          False           True   \n",
       " 1441          False          False          False          False   \n",
       " 4510          False          False          False          False   \n",
       " 39            False          False          False          False   \n",
       " 4509          False          False           True          False   \n",
       " ...             ...            ...            ...            ...   \n",
       " 9956          False          False          False          False   \n",
       " 1561          False          False          False          False   \n",
       " 1670          False          False          False          False   \n",
       " 6951          False          False          False          False   \n",
       " 3910          False           True          False          False   \n",
       " \n",
       "       order_month_7  order_month_8  order_month_9  order_month_10  \\\n",
       " 3125          False          False          False           False   \n",
       " 1441          False          False          False           False   \n",
       " 4510          False          False          False           False   \n",
       " 39            False          False          False           False   \n",
       " 4509          False          False          False           False   \n",
       " ...             ...            ...            ...             ...   \n",
       " 9956          False          False          False           False   \n",
       " 1561          False          False           True           False   \n",
       " 1670          False          False          False            True   \n",
       " 6951          False          False          False           False   \n",
       " 3910          False          False          False           False   \n",
       " \n",
       "       order_month_11  order_month_12  \n",
       " 3125           False           False  \n",
       " 1441           False            True  \n",
       " 4510            True           False  \n",
       " 39             False            True  \n",
       " 4509           False           False  \n",
       " ...              ...             ...  \n",
       " 9956            True           False  \n",
       " 1561           False           False  \n",
       " 1670           False           False  \n",
       " 6951            True           False  \n",
       " 3910           False           False  \n",
       " \n",
       " [1999 rows x 36 columns],\n",
       " 3125     21.1428\n",
       " 1441     11.4600\n",
       " 4510     17.1580\n",
       " 39      -15.1470\n",
       " 4509     -6.4233\n",
       "           ...   \n",
       " 9956     21.7845\n",
       " 1561      0.7228\n",
       " 1670      5.2125\n",
       " 6951     55.9986\n",
       " 3910   -211.4700\n",
       " Name: profit, Length: 1999, dtype: float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    'sales', 'quantity', \"original_price_per_unit\", \"markdown_amount\",\n",
    "    'sub_category', 'region', 'segment', 'order_month'\n",
    "]\n",
    "target = 'profit'\n",
    "model_training_refined(df, features, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
