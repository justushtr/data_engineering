{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "def model_training_tuning_extended(df_ml, features: list, target: str):\n",
    "    X = df_ml[features]\n",
    "    y = df_ml[target]\n",
    "    categorical_features = ['sub_category', 'region', 'segment','order_month']\n",
    "\n",
    "    ## One-Hot Encoding\n",
    "    X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
    "\n",
    "    models = {\n",
    "        \"LinearRegression\": LinearRegression(),\n",
    "        \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "        \"GradientBoosting\": GradientBoostingRegressor(random_state=42)\n",
    "    }\n",
    "\n",
    "    ## Erweiterter Parameterraum\n",
    "    param_grids = {\n",
    "        \"LinearRegression\": {}, \n",
    "        \n",
    "        \"RandomForest\": {\n",
    "            'n_estimators': [200, 500],        \n",
    "            'max_depth': [10, 20, 30, None],\n",
    "            'min_samples_split': [2, 5, 10],  \n",
    "            'min_samples_leaf': [1, 2, 4]     \n",
    "        },\n",
    "        \n",
    "        \"GradientBoosting\": {\n",
    "            'n_estimators': [200, 500],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'subsample': [0.8, 1.0] \n",
    "        }\n",
    "    }\n",
    "\n",
    "    ## Metriken\n",
    "    scoring_metrics = {\n",
    "        'R2': 'r2',\n",
    "        'MAE': 'neg_mean_absolute_error',\n",
    "        'RMSE': 'neg_root_mean_squared_error'\n",
    "    }\n",
    "\n",
    "    results_summary = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Starte Tuning für: {name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        if not param_grids[name]:\n",
    "            ## Fallback für LinearRegression ohne Grid\n",
    "            from sklearn.model_selection import cross_validate\n",
    "            scores = cross_validate(model, X_encoded, y, cv=5, scoring=scoring_metrics)\n",
    "            print(f\"Keine Parameter zu tunen. Standard-Ergebnisse:\")\n",
    "            print(f\"R2: {scores['test_R2'].mean():.4f} | MAE: {-scores['test_MAE'].mean():.2f} | RMSE: {-scores['test_RMSE'].mean():.2f}\")\n",
    "            results_summary[name] = model.fit(X_encoded, y)\n",
    "            continue\n",
    "\n",
    "        ## GridSearchCV Setup\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grids[name],\n",
    "            cv=5,\n",
    "            scoring=scoring_metrics,\n",
    "            refit='R2',\n",
    "            n_jobs=-1,\n",
    "            verbose=1 \n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_encoded, y)\n",
    "        \n",
    "        ## Auswertung Aller Kombinationen\n",
    "        results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "        \n",
    "        ## Wählen der relevanten Spalten für den Print\n",
    "        cols_to_keep = ['params', 'mean_test_R2', 'mean_test_MAE', 'mean_test_RMSE']\n",
    "        view_df = results_df[cols_to_keep].copy()\n",
    "        \n",
    "        ## Positiv machen\n",
    "        view_df['mean_test_MAE'] = -view_df['mean_test_MAE']\n",
    "        view_df['mean_test_RMSE'] = -view_df['mean_test_RMSE']\n",
    "        \n",
    "        ## Sortieren nach R2 (bestes oben)\n",
    "        view_df = view_df.sort_values(by='mean_test_R2', ascending=False)\n",
    "\n",
    "        print(f\"\\nAlle getesteten Kombinationen für {name} (Top 10 Auszug):\")\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"{'R2':<10} | {'MAE':<10} | {'RMSE':<10} | {'Parameters'}\")\n",
    "        print(\"-\" * 100)\n",
    "        \n",
    "        ## Iterieren und printen \n",
    "        for index, row in view_df.iterrows():\n",
    "            params_str = str(row['params'])\n",
    "            print(f\"{row['mean_test_R2']:<10.4f} | {row['mean_test_MAE']:<10.2f} | {row['mean_test_RMSE']:<10.2f} | {params_str}\")\n",
    "\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"BESTER {name}: R2={grid_search.best_score_:.4f}\")\n",
    "        print(f\"Beste Params: {grid_search.best_params_}\")\n",
    "        \n",
    "        results_summary[name] = grid_search.best_estimator_\n",
    "\n",
    "    return results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_training_tuning_extended' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m features \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_price_per_unit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown_amount\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub_category\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m ]\n\u001b[0;32m      5\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofit\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m best_models \u001b[38;5;241m=\u001b[39m model_training_tuning_extended(df, features, target)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_models)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_training_tuning_extended' is not defined"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'sales', 'quantity', \"original_price_per_unit\", \"markdown_amount\",\n",
    "    'sub_category', 'region', 'segment', 'order_month'\n",
    "]\n",
    "target = 'profit'\n",
    "best_models = model_training_tuning_extended(df, features, target)\n",
    "print(best_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trianing(df_ml, features : list, target : str):\n",
    "    X = df_ml[features]\n",
    "    y = df_ml[target]\n",
    "    categorical_features = ['sub_category', 'region', 'segment','order_month']\n",
    "\n",
    "    X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
    "    \n",
    "    models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "        max_depth=20,        \n",
    "        min_samples_leaf=2, \n",
    "        min_samples_split=5,\n",
    "        n_estimators=500, \n",
    "        random_state=42, \n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(\n",
    "        n_estimators=500, \n",
    "        random_state=42, \n",
    "        subsample=0.8\n",
    "    ),\n",
    "    }\n",
    "\n",
    "    print(f\"{'Model':<20} | {'R2 Score (Mean)':<15} | {'MAE (Mean USD)':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for name, model in models.items():\n",
    "        cv_r2 = cross_val_score(model, X_encoded, y, cv=5, scoring='r2')\n",
    "        cv_mae = cross_val_score(model, X_encoded, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "        print(f\"{name:<20} | {cv_r2.mean():<15.4f} | {-cv_mae.mean():<15.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beste Feature-Wahl: features = 'sales', 'quantity', \"original_price_per_unit\", \"markdown_amount\", 'sub_category', 'region', 'segment', 'order_month'\n",
    "\n",
    "Beste Parameter RF:  max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=500, random_state=42, \n",
    "\n",
    "Beste Parameter GB:  n_estimators=500, random_state=42, subsample=0.8\n",
    "\n",
    "Bestes Modell bei dieser Kombination: GB mit R2-SCore 0.8648 und MAE 16.59\n",
    "\n",
    "Problem: MAE ist fast doppelt so groß wie Median Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                | R2 Score (Mean) | MAE (Mean USD) \n",
      "------------------------------------------------------------\n",
      "LinearRegression     | 0.7270          | 37.15          \n",
      "RandomForest         | 0.7142          | 19.33          \n",
      "GradientBoosting     | 0.8648          | 16.59          \n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'sales', 'quantity', \"original_price_per_unit\", \"markdown_amount\",\n",
    "    'sub_category', 'region', 'segment', 'order_month'\n",
    "]\n",
    "target = 'profit'\n",
    "model_trianing(df, features, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
